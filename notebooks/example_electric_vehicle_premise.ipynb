{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-explicit LCA of an electric vehicle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use `bw_timex` with a cradle-to-grave case study of an electric vehicle (ev). The case study is simplified, not meant to reflect the complexity of electric mobility but to demonstrate how to use `bw_timex`. \n",
    "\n",
    "> **Note:** This is the \"premise\" version of this notebook that works with ecoinvent and premise data. If you don't have access to that, please check out the [\"standalone\" version](https://github.com/brightway-lca/bw_timex/blob/main/notebooks/example_electric_vehicle_standalone.ipynb) of this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bd\n",
    "\n",
    "bd.projects.set_current(\"timex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prospective background databases\n",
    "\n",
    "The `bw_timex` package itself does not provide any data - specifying prospective and dynamic information is up to the user. In this example, we use data from [ecoinvent v3.10](https://ecoinvent.org/), and create a set of prospective databases with [`premise`](https://github.com/polca/premise). We applied projections for the future electricity sectors using the SSP2-RCP19 pathway from the IAM IMAGE. We selected this pathway to simply demonstrate some future development in this case study, and many other models and pathways are available. \n",
    "In the [premise documentation](https://premise.readthedocs.io/en/latest/) you can find instructions for the creation of prospective background databases. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_2020 = bd.Database(\"ei310_IMAGE_SSP2_RCP19_2020_electricity\")\n",
    "db_2030 = bd.Database(\"ei310_IMAGE_SSP2_RCP19_2030_electricity\")\n",
    "db_2040 = bd.Database(\"ei310_IMAGE_SSP2_RCP19_2040_electricity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this study, we consider the following production system for our ev. Purple boxes are foreground, cyan boxes are background (i.e., ecoinvent/premise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart LR\n",
    "    glider_production(glider production):::ei-->ev_production\n",
    "    powertrain_production(powertrain production):::ei-->ev_production\n",
    "    battery_production(battery production):::ei-->ev_production\n",
    "    ev_production(ev production):::fg-->driving\n",
    "    electricity_generation(electricity generation):::ei-->driving\n",
    "    driving(driving):::fg-->used_ev\n",
    "    used_ev(used ev):::fg-->glider_eol(glider eol):::ei\n",
    "    used_ev-->powertrain_eol(powertrain eol):::ei\n",
    "    used_ev-->battery_eol(battery eol):::ei\n",
    "\n",
    "    classDef ei color:#222832, fill:#3fb1c5, stroke:none;\n",
    "    classDef fg color:#222832, fill:#9c5ffd, stroke:none;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the production system\n",
    "\n",
    "Now, we need to build this with brightway. If you are not interested in the modeling details, feel free to skip this section.\n",
    "\n",
    "For our ev model we make the following assumptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELECTRICITY_CONSUMPTION = 0.2 # kWh/km\n",
    "MILEAGE = 150_000 # km\n",
    "LIFETIME = 15 # years\n",
    "\n",
    "# Overall mass: 1200 kg\n",
    "MASS_GLIDER = 840 # kg\n",
    "MASS_POWERTRAIN = 80 # kg\n",
    "MASS_BATTERY = 280 # kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a new foreground database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"foreground\" in bd.databases:\n",
    "    del bd.databases[\"foreground\"] # to make sure we create the foreground from scratch\n",
    "foreground = bd.Database(\"foreground\")\n",
    "foreground.register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's creating the foreground activities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_production = foreground.new_node(\"ev_production\", name=\"production of an electric vehicle\", unit=\"unit\")\n",
    "ev_production['reference product'] = \"electric vehicle\"\n",
    "ev_production.save()\n",
    "\n",
    "driving = foreground.new_node(\"driving\", name=\"driving an electric vehicle\", unit=\"transport over an ev lifetime\")\n",
    "driving['reference product'] = \"transport\"\n",
    "driving.save()\n",
    "\n",
    "used_ev = foreground.new_node(\"used_ev\", name=\"used electric vehicle\", unit=\"unit\")\n",
    "used_ev['reference product'] = \"used electric vehicle\"\n",
    "used_ev.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the actual process data from ecoinvent. However, the ecoinvent processes for the ev part production contain exchanges for the end of life treatment in the production processes already, which we want to separate. So let's fix that first by creating new activities without the eol processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for db in [db_2020, db_2030, db_2040]:\n",
    "    for code in [\"glider_production_without_eol\", \"powertrain_production_without_eol\", \"battery_production_without_eol\"]:\n",
    "        try:\n",
    "            act = db.get(code=code)\n",
    "            act.delete()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    glider_production = db.get(name=\"glider production, passenger car\")\n",
    "    glider_production_without_eol = glider_production.copy(code=\"glider_production_without_eol\", database=db.name)\n",
    "    glider_production_without_eol[\"name\"] = \"glider production, passenger car, without EOL\"\n",
    "    # glider_production_without_eol[\"reference product\"] = \"glider\"\n",
    "    glider_production_without_eol.save()\n",
    "    for exc in glider_production_without_eol.exchanges():\n",
    "        if exc.input[\"name\"] == \"market for used glider, passenger car\":\n",
    "            exc.delete()\n",
    "    \n",
    "    powertrain_production = db.get(name=\"powertrain production, for electric passenger car\")\n",
    "    powertrain_production_without_eol = powertrain_production.copy(code=\"powertrain_production_without_eol\", database=db.name)\n",
    "    powertrain_production_without_eol[\"name\"] = \"powertrain production, for electric passenger car, without EOL\"\n",
    "    # powertrain_production_without_eol[\"reference product\"] = \"powertrain\"\n",
    "    powertrain_production_without_eol.save()\n",
    "    for exc in powertrain_production_without_eol.exchanges():\n",
    "        if exc.input[\"name\"] == \"market for used powertrain from electric passenger car, manual dismantling\":\n",
    "            exc.delete()\n",
    "    \n",
    "    battery_production = db.get(name=\"battery production, Li-ion, LiMn2O4, rechargeable, prismatic\")\n",
    "    battery_production_without_eol = battery_production.copy(code=\"battery_production_without_eol\", database=db.name)\n",
    "    battery_production_without_eol[\"name\"] = \"battery production, Li-ion, LiMn2O4, rechargeable, prismatic, without EOL\"\n",
    "    # battery_production_without_eol[\"reference product\"] = \"battery\"\n",
    "    battery_production_without_eol.save()\n",
    "    # For the battery, some waste treatment is buried in the process \"battery cell production, Li-ion, \n",
    "    # LiMn2O4\" - but not for the whole mass of the battery(?). For simplicity, we just leave it in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build the exchanges, starting with the ev production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glider_production = db_2020.get(code=\"glider_production_without_eol\")\n",
    "powertrain_production = db_2020.get(code=\"powertrain_production_without_eol\")\n",
    "battery_production = db_2020.get(code=\"battery_production_without_eol\")\n",
    "\n",
    "ev_production.new_edge(input=ev_production, amount=1, type=\"production\").save()\n",
    "\n",
    "glider_to_ev = ev_production.new_edge(\n",
    "    input=glider_production,\n",
    "    amount=MASS_GLIDER, \n",
    "    type=\"technosphere\"\n",
    ")\n",
    "powertrain_to_ev = ev_production.new_edge(\n",
    "    input=powertrain_production, \n",
    "    amount=MASS_POWERTRAIN, \n",
    "    type=\"technosphere\"\n",
    ")\n",
    "battery_to_ev = ev_production.new_edge(\n",
    "    input=battery_production, \n",
    "    amount=MASS_BATTERY, \n",
    "    type=\"technosphere\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... the end of life:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glider_eol = db_2020.get(name=\"treatment of used glider, passenger car, shredding\")\n",
    "powertrain_eol = db_2020.get(name=\"treatment of used powertrain for electric passenger car, manual dismantling\")\n",
    "battery_eol = db_2020.get(name=\"market for used Li-ion battery\")\n",
    "\n",
    "used_ev.new_edge(input=used_ev, amount=-1, type=\"production\").save()  # -1 as this gets rid of a used car\n",
    "\n",
    "used_ev_to_glider_eol = used_ev.new_edge(\n",
    "    input=glider_eol,\n",
    "    amount=-MASS_GLIDER,\n",
    "    type=\"technosphere\",\n",
    ")\n",
    "used_ev_to_powertrain_eol = used_ev.new_edge(\n",
    "    input=powertrain_eol,\n",
    "    amount=-MASS_POWERTRAIN,\n",
    "    type=\"technosphere\",\n",
    ")\n",
    "used_ev_to_battery_eol = used_ev.new_edge(\n",
    "    input=battery_eol,\n",
    "    amount=-MASS_BATTERY,\n",
    "    type=\"technosphere\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and, finally, driving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_production = db_2020.get(name=\"market group for electricity, low voltage\", location=\"WEU\")\n",
    "\n",
    "driving.new_edge(input=driving, amount=1, type=\"production\").save()\n",
    "\n",
    "driving_to_used_ev = driving.new_edge(input=used_ev, amount=-1, type=\"technosphere\")\n",
    "ev_to_driving = driving.new_edge(\n",
    "    input=ev_production, \n",
    "    amount=1, \n",
    "    type=\"technosphere\"\n",
    ")\n",
    "electricity_to_driving = driving.new_edge(\n",
    "    input=electricity_production,\n",
    "    amount=ELECTRICITY_CONSUMPTION * MILEAGE,\n",
    "    type=\"technosphere\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding temporal information\n",
    "\n",
    "Now that the production system is modelled, we can add temporal distributions at the exchange level. The temporal information we want to embed in our product system looks somewhat like this:\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "    glider_production(glider production):::ei-->|0-2 years prior|ev_production\n",
    "    powertrain_production(powertrain production):::ei-->|1 year prior|ev_production\n",
    "    battery_production(battery production):::ei-->|1 year prior|ev_production\n",
    "    ev_production(ev production):::fg-->|0-3 months prior|driving\n",
    "    electricity_generation(electricity generation):::ei-->|uniformly distributed \\n over lifetime|driving\n",
    "    driving(driving):::fg-->|after ev lifetime|used_ev\n",
    "    used_ev(used ev):::fg-->|3 months after \\n ev lifetime|glider_eol(glider eol):::ei\n",
    "    used_ev-->|3 months after \\n ev lifetime|powertrain_eol(powertrain eol):::ei\n",
    "    used_ev-->|3 months after \\n ev lifetime|battery_eol(battery eol):::ei\n",
    "\n",
    "    classDef ei color:#222832, fill:#3fb1c5, stroke:none;\n",
    "    classDef fg color:#222832, fill:#9c5ffd, stroke:none;\n",
    "```\n",
    "\n",
    "To include this temopral information, we use the `TemporalDistribution` class from `bw_temporalis`. For more info, take a look at the [bw_temporalis documentation](https://github.com/brightway-lca/bw_temporalis).\n",
    "\n",
    "Notably, in addition to the timestamp of the occurence of the process (which is shown in the flowchart above), we also need to specify the amount share of the exchange that happens at that time to fully define a `TemporalDistribution`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bw_temporalis import TemporalDistribution, easy_timedelta_distribution\n",
    "import numpy as np\n",
    "\n",
    "td_assembly_and_delivery = TemporalDistribution(\n",
    "    date=np.array([-3, -2], dtype=\"timedelta64[M]\"), amount=np.array([0.2, 0.8])\n",
    ")\n",
    "\n",
    "td_glider_production = TemporalDistribution(\n",
    "    date=np.array([-2, -1, 0], dtype=\"timedelta64[Y]\"), amount=np.array([0.7, 0.1, 0.2])\n",
    ")\n",
    "\n",
    "td_produce_powertrain_and_battery = TemporalDistribution(\n",
    "    date=np.array([-1], dtype=\"timedelta64[Y]\"), amount=np.array([1])\n",
    ")\n",
    "\n",
    "td_use_phase = easy_timedelta_distribution(\n",
    "    start=0,\n",
    "    end=LIFETIME,\n",
    "    resolution=\"Y\",\n",
    "    steps=(LIFETIME + 1),\n",
    "    kind=\"uniform\", # you can also do \"normal\" or \"triangular\" distributions\n",
    ")\n",
    "\n",
    "td_disassemble_used_ev = TemporalDistribution(\n",
    "    date=np.array([LIFETIME + 1], dtype=\"timedelta64[Y]\"), amount=np.array([1])\n",
    ")\n",
    "\n",
    "td_treating_waste = TemporalDistribution(\n",
    "    date=np.array([3], dtype=\"timedelta64[M]\"), amount=np.array([1])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore what a `TemporalDistribution` looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_assembly_and_delivery.graph(resolution=\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_glider_production.graph(resolution=\"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the functional unit in our supply chain graph, the temporal distributions of consecutive edges get \"multiplied\", or more specifically, convolved. Let's look at an example to clarify this. The assembly and delivery of our ev happens either 2 or 3 months before we can start using it. Each of these occurences of this process demands a glider, which also has a temporal distribution that then gets convolved \"back in time\". Also pay attention to how the amounts get scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(td_assembly_and_delivery * td_glider_production).graph(resolution=\"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add the temporal information to the exchanges of our EV. We add temporal distributions to all (technosphere) exchanges, but you don't have to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glider_to_ev[\"temporal_distribution\"] = td_glider_production\n",
    "glider_to_ev.save()\n",
    "\n",
    "powertrain_to_ev[\"temporal_distribution\"] = td_produce_powertrain_and_battery\n",
    "powertrain_to_ev.save()\n",
    "\n",
    "battery_to_ev[\"temporal_distribution\"] = td_produce_powertrain_and_battery\n",
    "battery_to_ev.save()\n",
    "\n",
    "ev_to_driving[\"temporal_distribution\"] = td_assembly_and_delivery\n",
    "ev_to_driving.save()\n",
    "\n",
    "electricity_to_driving[\"temporal_distribution\"] = td_use_phase\n",
    "electricity_to_driving.save()\n",
    "\n",
    "driving_to_used_ev[\"temporal_distribution\"] = td_disassemble_used_ev\n",
    "driving_to_used_ev.save()\n",
    "\n",
    "used_ev_to_glider_eol[\"temporal_distribution\"] = td_treating_waste\n",
    "used_ev_to_glider_eol.save()\n",
    "\n",
    "used_ev_to_powertrain_eol[\"temporal_distribution\"] = td_treating_waste\n",
    "used_ev_to_powertrain_eol.save()\n",
    "\n",
    "used_ev_to_battery_eol[\"temporal_distribution\"] = td_treating_waste\n",
    "used_ev_to_battery_eol.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCA using `bw_timex`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we need to select an impact assessment method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = ('EF v3.1', 'climate change', 'global warming potential (GWP100)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bw_timex` also needs to know the representative time of the databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "database_dates = {\n",
    "    db_2020.name: datetime.strptime(\"2020\", \"%Y\"),\n",
    "    db_2030.name: datetime.strptime(\"2030\", \"%Y\"),\n",
    "    db_2040.name: datetime.strptime(\"2040\", \"%Y\"),\n",
    "    \"foreground\": \"dynamic\", # flag databases that should be temporally distributed with \"dynamic\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can instantiate a `TimexLCA`. It's structure is similar to a normal `bw2calc.LCA`, but with the additional argument `database_dates`.\n",
    "\n",
    "Not sure about the required inputs? Check the documentation using `?`. All our classes and methods have docstrings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bw_timex import TimexLCA\n",
    "TimexLCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate a `TimexLCA` object for our \"driving\" activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlca = TimexLCA({driving: 1}, method, database_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build a timeline of the exchanges. To do this, we can call the `build_timeline()` method, which does the graph traversal and creates a timeline dataframe from the results. The exchanges (rows of the dataframe) are aggregated to the resolution specified in the argument `temporal_grouping`. There are also many more options to specify the timeline creation and graph traversal process. Here are the most important ones:\n",
    "- `temporal_grouping`: temporal resolution to which processes will be aggregated,\"year\" (default), \"month\", \"day\" or \"hour\"\n",
    "- `interpolation_type`: How the best fitting background database is selected: \"linear\"(default), \"closest\"\n",
    "- `edge_filter_function`: Custom filter function specifying when to stop the graph traversal.\n",
    "- `cutoff`: stops graph traversal for nodes below this contribution to the static impact score.\n",
    "- `max_calc`: stops graph traversal if this number of nodes has been traversed\n",
    "\n",
    "For all these options, we provide sensible default values. Of course you can always just check the docstrings to see all your options and our assumptions for default values. \n",
    "\n",
    "So, let's build the timeline. We choose a monthly temporal grouping here because we use that resolution in our temporal distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlca.build_timeline(temporal_grouping=\"month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temporal market shares in the timeline (right most column above) specify the share of the amount of an exchange to be sourced from the respective database. \n",
    "`None` means that the exchange is in the foreground supply chain, and not at the intersection with the background system.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate the time-explicit LCI. The `TimexLCA.lci()` function takes care of all the relinking, based on the information from the timeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlca.lci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlca.dynamic_lcia(metric=\"radiative_forcing\", fixed_time_horizon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlca.dynamic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlca.characterized_inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import pandas as pd\n",
    "from bw_timex.utils import round_datetime, resolve_temporalized_node_name\n",
    "def create_plot_df(lca):\n",
    "    # Cache activity names\n",
    "    activity_name_cache = {\n",
    "        activity: resolve_temporalized_node_name(\n",
    "            lca.activity_time_mapping.reversed[activity][0][1]\n",
    "        )\n",
    "        for activity in lca.characterized_inventory[\"activity\"].unique()\n",
    "    }\n",
    "\n",
    "    # Prepare life cycle stage mapping\n",
    "    life_cycle_stage_mapping = {\n",
    "        \"battery production, Li-ion, LiMn2O4, rechargeable, prismatic, without EOL\": \"Production\",\n",
    "        \"glider production, passenger car, without EOL\": \"Production\",\n",
    "        \"market for used Li-ion battery\": \"EOL\",\n",
    "        \"market group for electricity, low voltage\": \"Use\",\n",
    "        \"powertrain production, for electric passenger car, without EOL\": \"Production\",\n",
    "        \"treatment of used glider, passenger car, shredding\": \"EOL\",\n",
    "        \"treatment of used powertrain for electric passenger car, manual dismantling\": \"EOL\",\n",
    "    }\n",
    "\n",
    "    # Process data\n",
    "    plot_data = (\n",
    "        lca.characterized_inventory\n",
    "        .assign(activity_label=lambda df: df[\"activity\"].map(activity_name_cache))\n",
    "        .groupby([\"date\", \"activity_label\"], as_index=False)\n",
    "        .sum()\n",
    "    )\n",
    "\n",
    "\n",
    "    plot_data[\"date\"] = plot_data[\"date\"].apply(partial(round_datetime, resolution=\"year\"))\n",
    "    plot_data[\"life_cycle_stage\"] = plot_data[\"activity_label\"].map(life_cycle_stage_mapping)\n",
    "\n",
    "    # Aggregate and pivot\n",
    "    final_data = (\n",
    "        plot_data.groupby([\"date\", \"life_cycle_stage\"], as_index=False)[\"amount\"]\n",
    "        # plot_data.groupby([\"date\", \"activity_label\"], as_index=False)[\"amount\"]\n",
    "        .sum()\n",
    "        .pivot(index=\"date\", columns=\"life_cycle_stage\", values=\"amount\")\n",
    "        # .pivot(index=\"date\", columns=\"activity_label\", values=\"amount\")\n",
    "        .reindex(columns=[\"Production\", \"Use\", \"EOL\"])\n",
    "    )\n",
    "\n",
    "    # final_data[\"Sum\"] = final_data.sum(axis=1)\n",
    "    \n",
    "    return final_data / 1e-11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal dynamic lca\n",
    "database_date_dict_dlca = {\n",
    "    db_2020.name: datetime.strptime(\"2020\", \"%Y\"),\n",
    "    \"foreground\": \"dynamic\", # flag databases that should be temporally distributed with \"dynamic\"\n",
    "}\n",
    "dlca = TimexLCA({driving: 1}, method, database_date_dict_dlca)\n",
    "dlca.build_timeline(temporal_grouping=\"month\")\n",
    "dlca.lci()\n",
    "dlca.dynamic_lcia(metric=\"radiative_forcing\", fixed_time_horizon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tlca = create_plot_df(tlca)\n",
    "df_dlca = create_plot_df(dlca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_tlca = pd.concat([pd.DataFrame({col: [0] for col in df_tlca.columns}, index=[datetime.strptime(\"20231231\", \"%Y%m%d\")]), df_tlca])\n",
    "df_dlca = pd.concat([pd.DataFrame({col: [0] for col in df_dlca.columns}, index=[datetime.strptime(\"20231231\", \"%Y%m%d\")]), df_dlca])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.style\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import NullLocator\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 6), sharex=True, sharey=True)\n",
    "colors = ['#00549F', '#F6A800', '#57AB27',  '#AAAAAA']\n",
    "labels = ['Production', 'Use', 'EOL']\n",
    "\n",
    "# Calculate global ylim\n",
    "all_data = pd.concat([df_tlca.fillna(0), df_dlca.fillna(0)])\n",
    "global_ylim = (0, 3.15)\n",
    "\n",
    "# Plot data\n",
    "df_tlca.fillna(0).plot(\n",
    "    ax=axes[0, 0],\n",
    "    linewidth=2,\n",
    "    xlim=(datetime(2018, 1, 1), datetime(2102, 1, 1)),\n",
    "    ylim=global_ylim,\n",
    "    color=colors,\n",
    "    legend=False,  # Suppress individual legends\n",
    ")\n",
    "df_dlca.fillna(0).plot(\n",
    "    ax=axes[0, 1],\n",
    "    linewidth=2,\n",
    "    xlim=(datetime(2018, 1, 1), datetime(2102, 1, 1)),\n",
    "    ylim=global_ylim,\n",
    "    color=colors,\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "# df_tlca.fillna(0).plot.area(\n",
    "#     ax=axes[1, 0],\n",
    "#     stacked=True,\n",
    "#     linewidth=0,\n",
    "#     xlim=(datetime(2018, 1, 1), datetime(2100, 1, 1)),\n",
    "#     ylim=global_ylim,\n",
    "#     color=colors,\n",
    "#     legend=False,\n",
    "# )\n",
    "axes[1, 0].stackplot(\n",
    "    df_tlca.index,\n",
    "    df_tlca[\"Production\"].fillna(0),\n",
    "    df_tlca[\"Use\"].fillna(0),\n",
    "    df_tlca[\"EOL\"].fillna(0),\n",
    "    labels=labels,\n",
    "    colors=colors,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "axes[1, 1].stackplot(\n",
    "    df_dlca.index,\n",
    "    df_dlca[\"Production\"].fillna(0),\n",
    "    df_dlca[\"Use\"].fillna(0),\n",
    "    df_dlca[\"EOL\"].fillna(0),\n",
    "    labels=labels,\n",
    "    colors=colors,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "# df_dlca.fillna(0).plot.area(\n",
    "#     ax=axes[1, 1],\n",
    "#     stacked=True,\n",
    "#     linewidth=0,\n",
    "#     xlim=(datetime(2018, 1, 1), datetime(2100, 1, 1)),\n",
    "#     ylim=global_ylim,\n",
    "#     color=colors,\n",
    "#     legend=False,\n",
    "# )\n",
    "\n",
    "fig.text(0.25, 1, \"time-explicit\", ha='center', fontsize=14)\n",
    "fig.text(0.75, 1, \"dynamic\", ha='center', fontsize=14)\n",
    "\n",
    "fig.text(-0.025, 0.7, \"individual\", ha='left', fontsize=14, rotation=90)\n",
    "fig.text(-0.025, 0.225, \"cumulative\", ha='left', fontsize=14, rotation=90)\n",
    "\n",
    "# top left\n",
    "# fig.text(0.04, 0.975, \"(a)\", ha='center')\n",
    "# fig.text(0.53, 0.975, \"(b)\", ha='center')\n",
    "# fig.text(0.04, 0.53, \"(c)\", ha='center')\n",
    "# fig.text(0.53, 0.53, \"(d)\", ha='center')\n",
    "\n",
    "# # top right\n",
    "fig.text(0.485, 0.935, \"(a)\", ha='center', fontsize=14, backgroundcolor='white')\n",
    "fig.text(0.9625, 0.935, \"(b)\", ha='center', fontsize=14, backgroundcolor='white')\n",
    "fig.text(0.485, 0.48, \"(c)\", ha='center', fontsize=14, backgroundcolor='white')\n",
    "fig.text(0.9625, 0.48, \"(d)\", ha='center', fontsize=14, backgroundcolor='white')\n",
    "\n",
    "axes[0, 0].set_ylabel(\"radiative forcing [10$^{-11}$ W m$^{-2}$]\")\n",
    "axes[1, 0].set_ylabel(\"radiative forcing [10$^{-11}$ W m$^{-2}$]\")\n",
    "\n",
    "axes[1, 0].set_xlabel(\"year\")\n",
    "axes[1, 1].set_xlabel(\"year\")\n",
    "\n",
    "# Create a single legend\n",
    "handles, labels = axes[1, 1].get_legend_handles_labels()\n",
    "fig.legend(\n",
    "    handles, labels, loc=\"upper center\", ncol=len(labels), bbox_to_anchor=(0.525, 0.04), frameon=False, markerscale=2\n",
    ")\n",
    "\n",
    "major_locator = mdates.YearLocator(10)  # Major ticks every 10 years\n",
    "minor_locator = mdates.YearLocator(10)  # Minor ticks every year\n",
    "\n",
    "for ax_rows in axes:\n",
    "    for ax in ax_rows:\n",
    "        ax.xaxis.set_major_locator(major_locator)\n",
    "        ax.xaxis.set_minor_locator(NullLocator())\n",
    "        ax.grid(which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "# for label in axes[1, 1].get_xticklabels():\n",
    "#     label.set_rotation(20)  # Rotate the labels\n",
    "#     label.set_ha('right')   # Set horizontal alignment to right\n",
    "\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a flag to plot the cumulative score over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlca.plot_dynamic_characterized_inventory(sum_activities=True, cumsum=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GWP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar options are available for the metric GWP, which compares the radiative forcing of a GHG to that of CO2 over a certain time horizon (commonly 100 years, but it can be set flexibly in `time_horizon`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlca.dynamic_lcia(metric=\"GWP\", fixed_time_horizon=False, time_horizon = 70)\n",
    "tlca.dynamic_score #kg CO2-eq (GWP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the GWP results over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlca.plot_dynamic_characterized_inventory(sum_emissions_within_activity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cumulative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlca.plot_dynamic_characterized_inventory(sum_emissions_within_activity=True, cumsum=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of time-explicit results to static results\n",
    "It's helpful to understand how the time-explicit results differ from those using static assessments. \n",
    "\n",
    "We compare the time-explicit results with those of an LCA for the year 2020 and 2040 for the standard GWP100 metric (time horizon=100 and no fixed time horizon). This means we neglect the additional differences of the time-explicit results that would arise from using dynamic LCIA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-explicit scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlca.dynamic_lcia(metric=\"GWP\", fixed_time_horizon=False, time_horizon=100)\n",
    "tlca.dynamic_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2020 (static) score has already been calculated by TimexLCA in the beginning, but we can still access the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlca.base_lca.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, further down we also want to look at what part of the life cycle has what contribution. To get this info, we need some more calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_scores = {}\n",
    "for exc in driving.technosphere():\n",
    "    if exc.input == ev_production:\n",
    "        for subexc in exc.input.technosphere():\n",
    "            tlca.base_lca.lcia(demand={subexc.input.id: exc.amount * subexc.amount * subexc.input.rp_exchange().amount})\n",
    "            static_scores[subexc.input[\"name\"]] = tlca.base_lca.score\n",
    "    elif exc.input == used_ev:\n",
    "        for subexc in exc.input.technosphere():\n",
    "            tlca.base_lca.lcia(demand={subexc.input.id: exc.amount * subexc.amount * subexc.input.rp_exchange().amount})\n",
    "            static_scores[subexc.input[\"name\"]] = tlca.base_lca.score\n",
    "    else:\n",
    "        tlca.base_lca.lcia(demand={exc.input.id: exc.amount})\n",
    "        static_scores[exc.input[\"name\"]] = tlca.base_lca.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we calculate the 2040 (prospective) scores by just changing the database the exchanges point to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2calc as bc\n",
    "\n",
    "# first create a copy of the system and relink to processes from 2040 database\n",
    "try:\n",
    "    prospective_driving = driving.copy(code=\"prospective_driving\", name=\"driving an electric vehi0cle in 2040\")\n",
    "except:\n",
    "    foreground.get(code=\"prospective_driving\").delete()\n",
    "    prospective_driving = driving.copy(code=\"prospective_driving\", name=\"driving an electric vehicle in 2040\")\n",
    "    \n",
    "\n",
    "for exc in prospective_driving.technosphere():\n",
    "    if exc.input == ev_production:\n",
    "        prospective_ev_production = ev_production.copy(name=\"production of an electric vehicle in 2040\")\n",
    "        exc.input = prospective_ev_production\n",
    "        exc.save()\n",
    "        for subexc in prospective_ev_production.technosphere():\n",
    "            subexc.input = bd.get_node(\n",
    "                database=db_2040.name,\n",
    "                name=subexc.input[\"name\"],\n",
    "                product=subexc.input[\"reference product\"],\n",
    "                location=subexc.input[\"location\"],\n",
    "            )\n",
    "            subexc.save()\n",
    "    elif exc.input == used_ev:\n",
    "        prospective_used_ev = used_ev.copy(name=\"used electric vehicle in 2040\")\n",
    "        exc.input = prospective_used_ev\n",
    "        exc.save()\n",
    "        for subexc in prospective_used_ev.technosphere():\n",
    "            subexc.input = bd.get_node(\n",
    "                database=db_2040.name,\n",
    "                name=subexc.input[\"name\"],\n",
    "                product=subexc.input[\"reference product\"],\n",
    "                location=subexc.input[\"location\"],\n",
    "            )\n",
    "            subexc.save()\n",
    "    else:\n",
    "        exc.input = bd.get_node(\n",
    "            database=db_2040.name,\n",
    "            name=exc.input[\"name\"],\n",
    "            product=exc.input[\"reference product\"],\n",
    "            location=exc.input[\"location\"],\n",
    "        )\n",
    "    exc.save()\n",
    "\n",
    "prospective_scores = {}\n",
    "lca = bc.LCA({prospective_driving.key: 1}, method)\n",
    "lca.lci(factorize=True)\n",
    "for exc in prospective_driving.technosphere():\n",
    "    if exc.input[\"name\"] in (prospective_ev_production[\"name\"], prospective_used_ev[\"name\"]):\n",
    "        for subexc in exc.input.technosphere():\n",
    "            lca.lcia(demand={subexc.input.id: exc.amount * subexc.amount * subexc.input.rp_exchange().amount})\n",
    "            prospective_scores[subexc.input[\"name\"]] = lca.score\n",
    "    else:\n",
    "        lca.lcia(demand={exc.input.id: exc.amount})\n",
    "        prospective_scores[exc.input[\"name\"]] = lca.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare the overall scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Static score: \", sum(static_scores.values())) # should be the same as tlca.base_lca.score\n",
    "print(\"Prospective score: \", sum(prospective_scores.values()))\n",
    "print(\"Time-explicit score: \", tlca.dynamic_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand what's going on, let's plot the scores as a waterfall chart  based on timing of emission. Also, we can look at the \"first-level contributions\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bw_timex.utils import plot_characterized_inventory_as_waterfall\n",
    "\n",
    "order_stacked_activities = (\n",
    "    [ \n",
    "        glider_production_without_eol[\"name\"],\n",
    "        battery_production_without_eol[\"name\"],\n",
    "        powertrain_production_without_eol[\"name\"],\n",
    "        electricity_production[\"name\"],\n",
    "        glider_eol[\"name\"],\n",
    "        battery_eol[\"name\"],\n",
    "        powertrain_eol[\"name\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "plot_characterized_inventory_as_waterfall(\n",
    "    tlca,\n",
    "    static_scores=static_scores,\n",
    "    prospective_scores=prospective_scores,\n",
    "    order_stacked_activities=order_stacked_activities,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that the time-explicit results (in the middle) are somewhere in between the static and the prospective results. This makes sense as at each timestep, the underlying processes are sourced from progressively \"cleaner\" background databases, reaching a lower impact than if they are only sourced from the current database, but not so low as the prospective results, which are fully sourced from the most decarbonized database. Notably, the electricity consumption in the use-phase, modelled uniformly over the lifetime of the EV, contributes less and less to the score in the later years, since the electricity becomes cleaner in the future databases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
